# @package _global_

defaults:
  - pop_play_kinematic_oracle_humanoid_spot_fp
  - /habitat/task/lab_sensors:
    # For the oracle navigation
    - has_finished_oracle_nav
  - /habitat/task/actions@habitat.task.actions.agent_0_pick_base_velocity: base_velocity
  - /habitat/task/actions@habitat.task.actions.agent_0_place_base_velocity: base_velocity
  - _self_

hydra:
  job:
    name: 'pop_play_humanoid_spot_fp'

habitat:
  gym:
    obs_keys:
      - agent_0_articulated_agent_arm_depth
      - agent_0_relative_resting_position
      - agent_0_obj_start_sensor
      - agent_0_obj_goal_sensor
      - agent_0_obj_start_gps_compass
      - agent_0_obj_goal_gps_compass
      - agent_0_is_holding
      - agent_0_ee_pos
      - agent_0_joint
      - agent_0_localization_sensor
      - agent_0_has_finished_oracle_nav
      - agent_0_other_agent_gps
      - agent_0_should_replan
      - agent_1_head_depth
      - agent_1_relative_resting_position
      - agent_1_obj_start_sensor
      - agent_1_obj_goal_sensor
      - agent_1_obj_start_gps_compass
      - agent_1_obj_goal_gps_compass
      - agent_1_is_holding
      - agent_1_ee_pos
      - agent_1_localization_sensor
      - agent_1_has_finished_oracle_nav
      - agent_1_other_agent_gps
      - agent_1_should_replan
  simulator:
    agents:
      agent_1:
        radius: 0.3
  task:
    desired_resting_position: [0.45, 0.0, 0.43]
    actions:
      agent_0_arm_action:
        type: "ArmAction"
        arm_controller: "ArmRelPosMaskKinematicAction"
        arm_joint_mask: [1,1,0,1,1,1,1]
        arm_joint_dimensionality: 7
        grasp_thresh_dist: 0.15
        disable_grip: False
        delta_pos_limit: 0.20
        ee_ctrl_lim: 0.015

      agent_0_base_velocity:
        lin_speed: 5.0
        ang_speed: 5.0
      agent_0_pick_base_velocity:
        lin_speed: 5.0
        ang_speed: 5.0
        gym_action_prefix: pick_base_vel
      agent_0_place_base_velocity:
        lin_speed: 5.0
        ang_speed: 5.0
        gym_action_prefix: place_base_vel

habitat_baselines:
  rl:
    policy:
      agent_0:
        hierarchical_policy:
          defined_skills:
            pick:
              skill_name: "PickSkillPolicy"
              obs_skill_inputs: ["obj_start_sensor"]
              load_ckpt_file: "multirun/checkpoints_jimmy/pick.pth"
              max_skill_steps: 200
              reset_joint_state: [0.0, -3.14, 0.0, 3.0, 0.0, 0.0, 0.0]
              apply_postconds: False
            place:
              skill_name: "PlaceSkillPolicy"
              obs_skill_inputs: ["obj_goal_sensor"]
              max_skill_steps: 500
              apply_postconds: False
              reset_joint_state: [0.0, -3.14, 0.0, 3.0, 0.0, 0.0, 0.0]
              load_ckpt_file: "multirun/checkpoints_jimmy/place.pth"
            nav_to_obj:
              skill_name: "NavSkillPolicy"
              obs_skill_inputs: ["goal_to_agent_gps_compass"]
              load_ckpt_file: "multirun/checkpoints_jimmy/jimmy_nav.pth"
              max_skill_steps: 500
              obs_skill_input_dim: 2
              pddl_action_names: ["nav_to_obj", "nav_to_goal", "nav_to_robot", "nav_to_receptacle_by_name"]
